import streamlit as st
import pandas as pd
import google.generativeai as genai
import json
import time
import io

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="TurkDetect AI - Gemini Powered", layout="wide")

# --- YARDIMCI FONKSÄ°YONLAR ---

def extract_names_from_chunk(names_chunk, api_key):
    """
    Bir grup (Ã¶rn: 50 adet) ismi Gemini'ye gÃ¶nderir ve TÃ¼rk olanlarÄ± JSON olarak ister.
    """
    try:
        genai.configure(api_key=api_key)
        
        # En hÄ±zlÄ± ve ucuz model: Flash
        model = genai.GenerativeModel(
            model_name='gemini-1.5-flash',
            generation_config={"response_mime_type": "application/json"}
        )

        prompt = f"""
        Act as a strictly deterministic data classifier.
        Below is a list of full names (First Name + Last Name).
        Identify which of these people are likely of TURKISH origin based on their names.
        
        Rules:
        1. Consider Turkish characters (ÄŸ, ÅŸ, Ä±, Ã¶, Ã¼, Ã§) even if written in ASCII (g, s, i, o, u, c).
        2. Look for Turkish linguistic patterns in first names and last names (suffixes like -oglu, -kaya, -demi, -er, -kan).
        3. Be strict. If unsure or if it's a common western name (e.g., 'Sarah Jones'), do not include it.
        4. "Can" is a Turkish name, but check the last name to confirm it's not English context.
        
        Input List:
        {json.dumps(names_chunk)}

        Output Format:
        Return a JSON object with a single key "turkish_names" containing the list of full names found.
        Example: {{"turkish_names": ["Ahmet Yilmaz", "Selin Demir"]}}
        """

        response = model.generate_content(prompt)
        
        # JSON yanÄ±tÄ±nÄ± parse et
        result = json.loads(response.text)
        return result.get("turkish_names", [])

    except Exception as e:
        st.error(f"API HatasÄ±: {e}")
        return []

# --- ARAYÃœZ ---
st.title("ğŸ¤– TurkDetect AI | Gemini API")
st.markdown("""
Bu araÃ§, **Gemini 1.5 Flash** modelini kullanarak yÃ¼klenen CSV dosyasÄ±ndaki kiÅŸilerin TÃ¼rk olup olmadÄ±ÄŸÄ±nÄ± analiz eder.
Herhangi bir isim sÃ¶zlÃ¼ÄŸÃ¼ kullanmaz, doÄŸrudan Yapay Zeka'nÄ±n kÃ¼ltÃ¼rel bilgisini kullanÄ±r.
""")

# Sidebar: API Key ve Ayarlar
with st.sidebar:
    st.header("ğŸ”‘ Kimlik DoÄŸrulama")
    api_key = st.text_input("Google Gemini API Key", type="password", help="aistudio.google.com adresinden alabilirsiniz.")
    
    st.markdown("---")
    st.header("âš™ï¸ Performans AyarlarÄ±")
    batch_size = st.slider("Batch Boyutu (Tek seferde sorulacak isim)", 20, 100, 50, help="YÃ¼ksek sayÄ± daha hÄ±zlÄ±dÄ±r ama model hata yapabilir.")
    request_delay = st.slider("Ä°stek Gecikmesi (Saniye)", 0.0, 2.0, 0.5, help="Rate Limit yememek iÃ§in bekleme sÃ¼resi.")

# Ana Ekran
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("ğŸ“ Dosya YÃ¼kle")
    uploaded_file = st.file_uploader("Apollo/LinkedIn CSV (Max 50k)", type=["csv"])

    if uploaded_file and api_key:
        df = pd.read_csv(uploaded_file)
        
        # Kolon Tespiti
        cols = [c.lower() for c in df.columns]
        fname_col = next((c for c in df.columns if c.lower() in ['first name', 'firstname', 'ad', 'name']), None)
        lname_col = next((c for c in df.columns if c.lower() in ['last name', 'lastname', 'soyad', 'surname']), None)

        if fname_col and lname_col:
            st.success(f"âœ… {len(df)} satÄ±r yÃ¼klendi. Kolonlar bulundu.")
            
            # Tam Ä°sim Kolonu OluÅŸtur (AI'ya bunu gÃ¶ndereceÄŸiz)
            df['Full_Name_Temp'] = df[fname_col].astype(str) + " " + df[lname_col].astype(str)
            all_names = df['Full_Name_Temp'].tolist()
            
            if st.button("ğŸš€ AI Analizini BaÅŸlat"):
                identified_turkish_names = []
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Batch Processing DÃ¶ngÃ¼sÃ¼
                total_batches = (len(all_names) + batch_size - 1) // batch_size
                
                for i in range(0, len(all_names), batch_size):
                    batch = all_names[i : i + batch_size]
                    
                    # API Ã‡aÄŸrÄ±sÄ±
                    found_names = extract_names_from_chunk(batch, api_key)
                    identified_turkish_names.extend(found_names)
                    
                    # UI GÃ¼ncelleme
                    current_batch = (i // batch_size) + 1
                    progress = min(current_batch / total_batches, 1.0)
                    progress_bar.progress(progress)
                    status_text.code(f"Ä°ÅŸleniyor: {current_batch}/{total_batches} Paket | Bulunan TÃ¼rk: {len(identified_turkish_names)}")
                    
                    # Rate Limit KorumasÄ±
                    time.sleep(request_delay)

                # --- SONUÃ‡ FÄ°LTRELEME ---
                # AI'dan dÃ¶nen isimleri orijinal veride iÅŸaretle
                # Performans iÃ§in Set'e Ã§eviriyoruz
                turkish_set = set(identified_turkish_names)
                
                # Orijinal dataframe'i filtrele
                result_df = df[df['Full_Name_Temp'].isin(turkish_set)].copy()
                
                # GeÃ§ici kolonu sil
                result_df.drop(columns=['Full_Name_Temp'], inplace=True)
                
                st.session_state['results'] = result_df
                st.session_state['processed'] = True

        else:
            st.error("CSV'de Ä°sim/Soyisim kolonu bulunamadÄ±.")
    elif uploaded_file and not api_key:
        st.warning("LÃ¼tfen sol menÃ¼den API Key giriniz.")

# SonuÃ§ EkranÄ± (Session State ile kalÄ±cÄ±)
if st.session_state.get('processed'):
    res = st.session_state['results']
    with col2:
        st.subheader("ğŸ¯ Analiz SonuÃ§larÄ±")
        st.info(f"Toplam {len(res)} TÃ¼rk profili tespit edildi.")
        
        st.dataframe(res, height=600)
        
        # Excel Ä°ndirme
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            res.to_excel(writer, index=False, sheet_name='Turkish Leads')
            
        st.download_button(
            label="ğŸ“¥ Excel Olarak Ä°ndir",
            data=buffer.getvalue(),
            file_name="gemini_filtered_leads.xlsx",
            mime="application/vnd.ms-excel"
        )
